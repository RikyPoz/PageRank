{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4f759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21de68c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_link_matrix(filename):\n",
    "    \"\"\"\n",
    "    Costruisce la Link Matrix in formato sparso (CSR).\n",
    "    NON applica fisicamente la patch nella matrice per preservare la sparsità,\n",
    "    ma identifica i nodi dangling per gestirli nel calcolo vettoriale.\n",
    "    \"\"\"\n",
    "    links = []\n",
    "    out_degree = {}\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            # 1. Lettura Header\n",
    "            header = file.readline().strip().split()\n",
    "            if not header: raise ValueError(\"File vuoto o header mancante\")\n",
    "            N = int(header[0])\n",
    "            \n",
    "            # 2. Skip URL mapping\n",
    "            for _ in range(N): file.readline()\n",
    "            \n",
    "            # 3. Lettura Archi\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 2:\n",
    "                    src, tgt = int(parts[0]), int(parts[1])\n",
    "                    out_degree[src] = out_degree.get(src, 0) + 1\n",
    "                    links.append((src, tgt))\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Errore lettura file: {e}\")\n",
    "        return None, 0, None\n",
    "\n",
    "    # Preparazione dati per matrice sparsa (Data, Row, Col)\n",
    "    data = []\n",
    "    rows = [] # Target (i)\n",
    "    cols = [] # Source (j)\n",
    "    \n",
    "    # Identifichiamo i nodi dangling (quelli che non hanno out_degree)\n",
    "    # Creiamo una maschera booleana: True se il nodo è dangling\n",
    "    is_dangling = np.ones(N, dtype=bool) \n",
    "    \n",
    "    for src, tgt in links:\n",
    "        src_idx = src - 1\n",
    "        tgt_idx = tgt - 1\n",
    "        \n",
    "        # Se siamo qui, il nodo src ha almeno un link, quindi non è dangling\n",
    "        is_dangling[src_idx] = False\n",
    "        \n",
    "        # Calcolo valore 1/n_j\n",
    "        val = 1.0 / out_degree[src]\n",
    "        \n",
    "        rows.append(tgt_idx)\n",
    "        cols.append(src_idx)\n",
    "        data.append(val)\n",
    "        \n",
    "    # Costruzione matrice CSR (Compressed Sparse Row)\n",
    "    # Nota: Usiamo CSR perché è molto veloce per la moltiplicazione matrice-vettore\n",
    "    A_sparse = sparse.csr_matrix((data, (rows, cols)), shape=(N, N))\n",
    "    \n",
    "    dangling_indices = np.where(is_dangling)[0]\n",
    "    print(f\"Matrice sparsa costruita: {N} nodi, {len(data)} link validi.\")\n",
    "    print(f\"Nodi dangling identificati: {len(dangling_indices)} (gestiti implicitamente).\")\n",
    "    \n",
    "    return A_sparse, N, dangling_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14eb3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pagerank_sparse(A_sparse, N, dangling_indices, m=0.15, max_iter=200, tol=1e-7):\n",
    "    \"\"\"\n",
    "    Calcola il PageRank usando operazioni sparse efficienti.\n",
    "    Gestisce la patch dei dangling nodes dinamicamente.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inizializzazione vettore x (1/N)\n",
    "    x = np.full(N, 1.0/N)\n",
    "    \n",
    "    # Vettore costante di teletrasporto (parte fissa m/N)\n",
    "    teleport_contribution = m / N\n",
    "    \n",
    "    # Pre-calcolo indici dangling per accesso veloce (se non passato come array)\n",
    "    if not isinstance(dangling_indices, np.ndarray):\n",
    "        dangling_indices = np.array(dangling_indices)\n",
    "        \n",
    "    iterations = 0\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        x_prev = x.copy()\n",
    "        \n",
    "        # 1. Moltiplicazione Standard su matrice sparsa\n",
    "        # Calcola solo i link ESISTENTI. Ignora i dangling nodes per ora (sono righe di zeri).\n",
    "        # Risultato parziale: flusso di probabilità dai nodi normali.\n",
    "        Ax = A_sparse.dot(x_prev)\n",
    "        \n",
    "        # 2. Gestione \"Virtuale\" dei Dangling Nodes\n",
    "        # Calcoliamo quanta probabilità è finita nei vicoli ciechi\n",
    "        dangling_mass_sum = np.sum(x_prev[dangling_indices])\n",
    "        \n",
    "        # Questa massa viene ridistribuita equamente a tutti i nodi (Patch 1/N)\n",
    "        # Deve essere smorzata dal fattore (1-m)\n",
    "        dangling_correction = (1 - m) * (dangling_mass_sum / N)\n",
    "        \n",
    "        # 3. Combinazione finale\n",
    "        # x = (flusso dai link * smorzamento) + (flusso dai dangling * smorzamento) + (teletrasporto random)\n",
    "        x = (1 - m) * Ax + dangling_correction + teleport_contribution\n",
    "        \n",
    "        # Check convergenza (Norma L1)\n",
    "        diff = np.sum(np.abs(x - x_prev))\n",
    "        iterations = k + 1\n",
    "        \n",
    "        if diff < tol:\n",
    "            break\n",
    "            \n",
    "    return x, iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f281426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AVVIO IMPLEMENTAZIONE SPARSA ---\n",
      "Matrice sparsa costruita: 6012 nodi, 23875 link validi.\n",
      "Nodi dangling identificati: 3189 (gestiti implicitamente).\n",
      "Calcolo completato in 71 iterazioni.\n",
      "\n",
      "--- TOP 10 Pages (Sparse Method) ---\n",
      "Rank 1: Page ID 2 (Score: 0.019879)\n",
      "Rank 2: Page ID 37 (Score: 0.009288)\n",
      "Rank 3: Page ID 38 (Score: 0.008610)\n",
      "Rank 4: Page ID 61 (Score: 0.008065)\n",
      "Rank 5: Page ID 52 (Score: 0.008027)\n",
      "Rank 6: Page ID 43 (Score: 0.007165)\n",
      "Rank 7: Page ID 425 (Score: 0.006583)\n",
      "Rank 8: Page ID 27 (Score: 0.005989)\n",
      "Rank 9: Page ID 28 (Score: 0.005572)\n",
      "Rank 10: Page ID 4023 (Score: 0.004452)\n",
      "\n",
      "Somma totale PageRank: 1.000000 (Atteso: 1.0)\n",
      "Minimum score (last page): 0.000058\n",
      "Theoretical minimum score (0.15/N): 0.000025\n"
     ]
    }
   ],
   "source": [
    "# --- PARAMETRI ---\n",
    "filename = 'hollins.dat'\n",
    "m = 0.15\n",
    "top_k = 10\n",
    "\n",
    "print(\"--- AVVIO IMPLEMENTAZIONE SPARSA ---\")\n",
    "\n",
    "# 1. Costruzione\n",
    "A_sparse, N, dangling_nodes = build_sparse_link_matrix(filename)\n",
    "\n",
    "# 2. Calcolo\n",
    "if A_sparse is not None:\n",
    "    pagerank_scores, iters = calculate_pagerank_sparse(A_sparse, N, dangling_nodes, m=m)\n",
    "\n",
    "    print(f\"Calcolo completato in {iters} iterazioni.\")\n",
    "\n",
    "    # 3. Risultati\n",
    "    page_ids = np.arange(1, N + 1)\n",
    "    results = list(zip(page_ids, pagerank_scores))\n",
    "    results_sorted = sorted(results, key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    print(f\"\\n--- TOP {top_k} Pages (Sparse Method) ---\")\n",
    "    for rank, (page_id, score) in enumerate(results_sorted[:top_k], 1):\n",
    "        print(f\"Rank {rank}: Page ID {page_id} (Score: {score:.6f})\")\n",
    "\n",
    "    # Verifica correttezza matematica (somma deve essere 1)\n",
    "    print(f\"\\nSomma totale PageRank: {np.sum(pagerank_scores):.6f} (Atteso: 1.0)\")\n",
    "    \n",
    "    # For a good evaluation, we print the importance of the least important node, which should approach the theoretical minimum score (m/N).\n",
    "min_score = results_sorted[-1][1]\n",
    "expected_min = m / N\n",
    "print(f\"Minimum score (last page): {min_score:.6f}\")\n",
    "print(f\"Theoretical minimum score ({m}/N): {expected_min:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
